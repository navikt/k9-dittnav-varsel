apiVersion: nais.io/v1
kind: Alert
metadata:
  name: {{app}}-alerts
  labels:
    team: {{team}}
  namespace: {{namespace}}
spec:
  receivers:
    slack:
      channel: {{slack-channel}}
      prependText: "{{{slack-notify-type}}}"
  alerts:
    - alert: Applikasjon nede
      severity: danger
      expr: up{app="{{app}}", job="kubernetes-pods-istio-secure"} == 0
      for: 2m
      description: "App \{{ $labels.app }} er nede i namespace \{{ $labels.kubernetes_namespace }}"
      action: "`kubectl describe pod \{{ $labels.kubernetes_pod_name }} -n \{{ $labels.kubernetes_namespace }} -c \{{ $labels.app }}` for events, og `kubectl logs \{{ $labels.kubernetes_pod_name }} -n \{{ $labels.kubernetes_namespace }} -c \{{ $labels.app }}` for logger"

    - alert: høy feilrate i logger
      severity: danger
      expr: (100 * sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="{{app}}",log_level=~"Warning|Error"}[3m])) / sum by (log_app, log_namespace) (rate(logd_messages_total{log_app="{{app}}"}[3m]))) > 10
      for: 3m
      action: "Sjekk loggene til app \{{ $labels.log_app }} i namespace \{{ $labels.log_namespace }}, for å se hvorfor det er så mye feil"

    - alert: "\{{ $labels.name }} feiler i \{{ $labels.app }}."
      severity: danger
      expr: floor(increase(spring_kafka_listener_seconds_count{result="failure", app="{{app}}"}[3m])) > 0
      for: 1m
      description: "Konsumering av melding i \{{ $labels.name }} feiler. Sjekk loggene for å finne ut hvorfor dette feiler."
      action: "`kubectl logs \{{ $labels.kubernetes_pod_name }} -n \{{ $labels.kubernetes_namespace }} -c \{{ $labels.app }}`"

    - alert: Helsesjekk feiler
      expr: floor(increase(http_server_requests_seconds_count{status!~"200", uri="/actuator/health", app="{{app}}"}[3m])) > 0
      severity: warning
      for: 2m
      desription: "Sjekk loggene for å se hvorfor helsesjekken feiler.`"
      action: "`kubectl logs \{{ $labels.kubernetes_pod_name }} -n \{{ $labels.kubernetes_namespace }} -c \{{ $labels.app }}`"
